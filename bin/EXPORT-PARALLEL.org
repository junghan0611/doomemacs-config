#+title: Denote Export 병렬 처리 시스템
#+date: [2025-10-28 Mon]
#+filetags: :denote:export:parallel:makefile:

* 개요

Denote 노트(org 파일)를 Hugo 마크다운으로 병렬 변환하는 시스템입니다.

** 목표
- 2000+ org 파일을 효율적으로 Hugo markdown으로 변환
- ox-hugo, bibliography, citations 완벽 지원
- 병렬 처리로 속도 개선

** 성능
- 파일: 2008개 (meta: 530, bib: 649, notes: 782, test: 47)
- 속도: 2 jobs → 0.1 files/sec, 8 jobs → 0.4 files/sec (예상)
- 품질: 100% 성공률

* 시도한 방법들

** 방법 1: 백그라운드 방식 (denote-export-parallel.sh)
*** 동작 방식
#+begin_src bash
# 각 파일마다 emacs 프로세스 시작
find ~/org -name "*.org" | \
  parallel -j 8 'emacs --batch --load batch.el {} 2>&1'
#+end_src

*** 결과
- ✅ 안정적: 1974개 파일 100% 성공
- ❌ 느림: emacs 시작 × 1974번
- ❌ 비효율: 패키지 로딩 × 1974번

** 방법 2: 서버 N개 방식 (denote-export-server-parallel.sh) - 실패
*** 동작 방식
#+begin_src bash
# N개의 emacs daemon 시작
for i in 1..8; do
  emacs --daemon=server-$i --load server.el
done

# parallel로 파일을 N개 서버에 분산
find ~/org -name "*.org" | \
  parallel -j 8 --pipe-part 'emacsclient -s server-{%} --eval ...'
#+end_src

*** 실패 원인
1. **서버 초기화 타이밍 문제**
   - 패키지 로딩(ox-hugo, denote, citar) 완료 전에 요청 전송
   - ready 플래그 없음

2. **복잡도 증가**
   - N개 서버 관리 복잡
   - 각 서버별 상태 확인 필요
   - 파일 분산 로직 필요

3. **파일명 처리 문제**
   - Denote 파일명: 한글 + 특수문자 (§, ¤, →)
   - bash 변수 전달 시 인코딩 문제

*** 결과
- ❌ export 실패: 빈 파일 (42 bytes) 생성
- ❌ 속도만 빠르고 품질 0%

** 방법 3: Makefile + 단일 daemon (최종 성공!) ✅
*** 핵심 아이디어
#+begin_quote
"여러 서버가 아니라, 단일 daemon + 병렬 client 호출"
#+end_quote

*** 동작 방식
#+begin_src bash
# 1. Daemon 1개만 시작 (패키지 로딩 1번)
emacs --daemon=export --load denote-export-server.el

# 2. 병렬로 client 호출
find ~/org -name "*.org" | \
  xargs -P 8 -I {} sh -c 'emacsclient -s export --eval "(denote-export-file \"{}\")"'
#+end_src

*** 성공 요인
1. **Emacs Lisp로 파일 제어**
   #+begin_src elisp
   (defun denote-export-file (file)
     "Export single org FILE to Hugo markdown."
     ;; Denote 파일명 처리
     ;; ox-hugo export
     ;; Bibliography 처리
     ;; 결과 반환
   )
   #+end_src

2. **단일 daemon 재사용**
   - 패키지 로딩 1번만
   - 모든 설정 공유
   - 안정적

3. **병렬 client 호출**
   - xargs 또는 GNU Parallel
   - 파일 경로를 elisp 함수에 전달
   - daemon은 요청만 처리

*** 결과
- ✅ 안정적: 47/47 파일 100% 성공
- ⚠️ 느림: 478초 (8분, 2 jobs)
- ✅ 품질: 완벽한 export (ox-hugo + bibliography + citations)

*** 문제점 발견
Emacs daemon은 싱글 스레드이므로 여러 client 요청을 순차 처리합니다:
#+begin_example
8 clients → 1 daemon (싱글 스레드) → 순차 처리 (blocking!)
#+end_example

해결책: 여러 daemon을 시작해서 진짜 병렬 처리 필요

** 방법 4: Makefile + 멀티 daemon (최종 성공!) ✅

*** 핵심 아이디어
#+begin_quote
"여러 daemon으로 Emacs 싱글 스레드 한계 극복"
#+end_quote

*** 동작 방식
#+begin_src bash
# 1. N개 Daemon 시작 (각각 독립적)
for i in 1..4; do
  emacs --daemon=export-$i --load server.el
done

# 2. 파일을 N개 daemon에 분산
files | awk '{print NR % 4 + 1, $0}' | \
  xargs -P 8 -n 2 sh -c 'emacsclient -s export-$1 --eval "(denote-export-file \"$2\")"'
#+end_src

*** 성공 요인
1. **진짜 병렬 처리**
   #+begin_example
   Daemon 1 (CPU 1-2) → 파일 1, 2
   Daemon 2 (CPU 3-4) → 파일 3, 4
   Daemon 3 (CPU 5-6) → 파일 5, 6
   Daemon 4 (CPU 7-8) → 파일 7, 8
   #+end_example

2. **싱글 스레드 한계 극복**
   - 각 daemon이 독립적으로 동작
   - 요청 대기 없음
   - CPU 코어 완전 활용

3. **Makefile 자동화**
   - 여러 daemon 시작/종료 자동화
   - 초기화 대기 자동화
   - 파일 분산 자동화

*** 결과
- ✅ 안정적: 47/47 파일 100% 성공
- ✅ 빠름: 175초 (3분, 8 jobs) → **2.7배 향상!**
- ✅ 품질: 완벽한 export (ox-hugo + bibliography + citations)

*** 성능 비교

| 방식 | Daemons | Jobs | 시간 | 속도 | 개선율 |
|------|---------|------|------|------|--------|
| 단일 daemon | 1 | 2 | 478초 | 0.098 files/sec | 기준 |
| **멀티 daemon** | **4** | **8** | **175초** | **0.269 files/sec** | **2.7배** |

* 최종 구조

** 파일 구성
#+begin_example
doomemacs-config/
├── denote-export.mk              # Makefile (단일 daemon, 느림)
├── denote-export-multi.mk        # Makefile (멀티 daemon, ⭐ 최종 버전)
└── bin/
    ├── denote-export-server.el   # Daemon 서버
    ├── denote-export-batch.el    # Batch 방식 (참고용)
    ├── EXPORT-PARALLEL.org       # 이 문서
    └── backup-20251028/          # 구버전 백업
        ├── denote-export-parallel.sh
        └── denote-export-server-parallel.sh
#+end_example

** 사용 방법 (⭐ 멀티 daemon 버전)
#+begin_src bash
# 도움말
make -f denote-export-multi.mk help

# 테스트 (test 폴더만, 47개 파일)
make -f denote-export-multi.mk test

# 전체 export (2008개 파일)
make -f denote-export-multi.mk all

# Daemon 상태 확인
make -f denote-export-multi.mk status

# 모든 daemon 종료
make -f denote-export-multi.mk clean
#+end_src

** 병렬 처리 확장
#+begin_src makefile
# denote-export-multi.mk에서 수정
NUM_DAEMONS := 8        # 4 → 8로 변경 (더 많은 daemon)
JOBS_PER_DAEMON := 2    # daemon당 job 수
# TOTAL_JOBS = 8 × 2 = 16 parallel jobs
#+end_src

* 기술적 세부사항

** Makefile 핵심 로직
#+begin_src makefile
# Daemon 시작 및 ready 대기
daemon-check:
	emacs --daemon=$(DAEMON_NAME) --load $(SERVER_SCRIPT)
	# 30초 동안 ready 플래그 대기
	while ! emacsclient -s $(DAEMON_NAME) --eval '(boundp '"'"'denote-export-server-ready)'; do
	  sleep 1
	done

# 병렬 export
export-test:
	find $(ORG_DIR)/test -name "*.org" | \
	  xargs -P $(JOBS_PER_DIR) -I {} sh -c \
	    'emacsclient -s $(DAEMON_NAME) --eval "(denote-export-file \"{}\")"'
#+end_src

** Emacs Lisp 핵심 함수
#+begin_src elisp
;; Ready 플래그
(setq denote-export-server-ready t)

;; Export 함수
(defun denote-export-file (file)
  "Export single org FILE to Hugo markdown."
  (condition-case err
      (let* ((denote-id (extract-denote-id-from-filename file))
             (section (get-org-hugo-section-from-path file)))

        ;; .dir-locals.el 적용
        (with-current-buffer (find-file-noselect file)
          (org-mode)
          (setq-local org-hugo-section section)

          ;; Export
          (let ((result (org-hugo-export-to-md)))
            ;; Denote ID로 rename
            (rename-file result (concat denote-id ".md"))
            (format "SUCCESS:%s:%s" file result))))
    (error
     (format "ERROR:%s:%s" file (error-message-string err)))))
#+end_src

** 핵심 차이점: xargs vs parallel

두 방식 모두 elisp로 파일을 처리하므로 동일하게 작동합니다:

#+begin_src bash
# xargs (표준, 어디서나 동작)
xargs -P 8 -I {} sh -c 'emacsclient -s daemon --eval "(denote-export-file \"{}\")"'

# GNU Parallel (빠르고 progress bar 지원)
parallel -j 8 'emacsclient -s daemon --eval "(denote-export-file \"{}\")"'
#+end_src

* 성능 분석

** 현재 성능 (2 jobs)
- 처리 시간: 478초 (8분)
- 처리 속도: 0.098 files/sec
- 파일 수: 47개

** 예상 성능

| Jobs | 속도 (files/sec) | 2008개 전체 시간 |
|------+------------------+------------------|
|    2 |              0.1 | 334분 (5.6시간) |
|    4 |              0.2 | 167분 (2.8시간) |
|    8 |              0.4 | 84분 (1.4시간)   |
|   16 |              0.8 | 42분              |

** 병목 요인
1. **Emacs 처리 속도** (ox-hugo, bibliography)
2. **서버 응답 시간** (Oracle Cloud Free Tier)
3. **파일 I/O**

** 개선 방향
- 더 빠른 서버로 테스트 (일반 노트북)
- Jobs 수 증가 (16까지)
- SSD 사용

* 참고 자료

** 영감을 받은 블로그
- Mads Hartmann (2016): [[https://blog.mads-hartmann.com/2016/07/03/exporting-org-from-make.html][Exporting org from Make]]
  - Makefile + Emacs daemon 패턴
  - xargs -P를 통한 병렬화

- 200ok.ch (2022): [[https://200ok.ch/posts/2022-07-04_org_export_using_emacsclient.html][Export org using emacsclient]]
  - emacsclient 활용법
  - Fallback 전략 (daemon 없을 때 batch mode)

** Emacs 커뮤니티 표준
- Makefile: 의존성 관리 및 빌드 자동화
- xargs -P: 병렬 처리 (GNU Parallel 불필요)
- emacsclient: Daemon 재사용으로 성능 향상

* 결론

** 핵심 교훈
1. **단순함이 최고**: 여러 서버보다 단일 daemon + 병렬 client
2. **Emacs Lisp로 제어**: bash 변수 전달의 한계 극복
3. **커뮤니티 표준 따르기**: Makefile + xargs 패턴

** 다음 단계
- [X] 전체 디렉토리(meta, bib, notes) export 테스트
- [X] File-local variables 처리 문제 해결
- [X] Python 병렬 처리 방식 구현
- [ ] CI/CD 통합

* 방법 5: Python 멀티프로세싱 + 멀티 daemon (최종 프로덕션!) ⭐

** 핵심 아이디어
#+begin_quote
"Python의 ProcessPoolExecutor로 NBSP 파일명 완벽 처리 + 멀티 daemon 진짜 병렬 처리"
#+end_quote

** 문제 발견: File-local variables

*** 증상
- 일부 org 파일에 =eval:= local variables 포함
- Interactive 프롬프트 요구로 export 중단
- daemon이 멈춰서 전체 처리 블록

*** 문제 파일 예시
#+begin_example
# * Local Variables :noexport:
# Local Variables:
# eval: (font-lock-mode 1)
# eval: (ten-font-lock-mode 1)
# End:
#+end_example

*** 해결 방법: denote-export-server.el 수정

=bin/denote-export-server.el:40-43= 에 추가:

#+begin_src elisp
;; Disable file-local variables interactive prompts
(setq enable-local-variables :safe)  ; Only allow safe local variables
(setq enable-local-eval nil)         ; Never eval file-local code
(setq enable-dir-local-variables t)  ; Keep dir-locals support
#+end_src

** Python 병렬 처리 구현

*** 파일: bin/denote-export-parallel.py

#+begin_src python
#!/usr/bin/env python3
"""
Denote Export Parallel - Python multiprocessing for NBSP-safe parallel export

This script handles Unicode filenames (including NBSP U+00A0) correctly
and manages multiple Emacs daemons for parallel processing.
"""

import os
import sys
import subprocess
import time
from pathlib import Path
from concurrent.futures import ProcessPoolExecutor, as_completed

def export_file_via_daemon(args):
    """Export a single file via emacsclient to a specific daemon."""
    file_path, daemon_id = args
    daemon_name = f"denote-export-daemon-{daemon_id}"

    # Escape quotes in file path for Elisp string
    file_path_escaped = str(file_path).replace('"', '\\"')
    elisp_cmd = f'(denote-export-file "{file_path_escaped}")'

    try:
        result = subprocess.run(
            ['emacsclient', '-s', daemon_name, '--eval', elisp_cmd],
            capture_output=True,
            text=True,
            timeout=180
        )

        basename = file_path.name
        if result.returncode == 0 and 'SUCCESS:' in result.stdout:
            print(f"✓ [D{daemon_id}] {basename}", flush=True)
            return True, basename
        else:
            print(f"✗ [D{daemon_id}] {basename}", flush=True)
            if result.returncode != 0:
                print(f"  Return code: {result.returncode}", flush=True)
            if result.stderr:
                print(f"  Stderr: {result.stderr[:200]}", flush=True)
            return False, basename
    except Exception as e:
        print(f"✗ [D{daemon_id}] {file_path.name} - Error: {e}")
        return False, file_path.name

def main():
    if len(sys.argv) < 3:
        print("Usage: denote-export-parallel.py <directory> <num_daemons>")
        sys.exit(1)

    directory = Path(sys.argv[1])
    num_daemons = int(sys.argv[2])

    if not directory.exists():
        print(f"Error: Directory not found: {directory}")
        sys.exit(1)

    # Get all .org files (Python handles Unicode perfectly)
    org_files = sorted(directory.glob("*.org"))
    total_files = len(org_files)

    print(f"[INFO] Found {total_files} files in {directory}", flush=True)
    print(f"[INFO] Using {num_daemons} parallel daemons", flush=True)
    print(flush=True)

    # Assign files to daemons (round-robin)
    file_daemon_pairs = []
    for idx, file_path in enumerate(org_files):
        daemon_id = (idx % num_daemons) + 1
        file_daemon_pairs.append((file_path, daemon_id))

    # Process in parallel
    start_time = time.time()
    success_count = 0
    error_count = 0

    with ProcessPoolExecutor(max_workers=num_daemons) as executor:
        futures = {executor.submit(export_file_via_daemon, pair): pair
                  for pair in file_daemon_pairs}

        for future in as_completed(futures):
            success, basename = future.result()
            if success:
                success_count += 1
            else:
                error_count += 1

    duration = time.time() - start_time
    speed = total_files / duration if duration > 0 else 0

    print()
    print(f"[INFO] ========================================")
    print(f"[INFO] Export completed!")
    print(f"[INFO] Success: {success_count}, Errors: {error_count}, Total: {total_files}")
    print(f"[INFO] Duration: {duration:.1f}s, Speed: {speed:.2f} files/sec")
    print(f"[INFO] ========================================")

    return 0 if error_count == 0 else 1

if __name__ == '__main__':
    sys.exit(main())
#+end_src

** 사용 방법

*** 1단계: Daemon 시작 (4개)
#+begin_src bash
for i in 1 2 3 4; do
  emacs --quick --daemon=denote-export-daemon-$i \
    --load ~/repos/gh/doomemacs-config/bin/denote-export-server.el &
done
sleep 5  # 초기화 대기
#+end_src

*** 2단계: 병렬 Export
#+begin_src bash
python3 ~/repos/gh/doomemacs-config/bin/denote-export-parallel.py \
  ~/org/meta 4
#+end_src

*** 3단계: Daemon 정리
#+begin_src bash
pkill -f "denote-export-daemon"
#+end_src

** Retry 실패 파일 스크립트

실패한 파일(timeout 등)을 재처리하는 스크립트:

*** 파일: /tmp/retry-failed.py

#+begin_src python
#!/usr/bin/env python3
"""Retry failed files with increased timeout"""

import subprocess
import sys
from pathlib import Path

# Read failed files from log
with open('/tmp/failed-files-paths.txt', 'r') as f:
    failed_files = [line.strip() for line in f if line.strip()]

print(f"[Retry] Found {len(failed_files)} failed files")
print(f"[Retry] Using daemon: denote-export-daemon-1")
print(f"[Retry] Timeout: 180 seconds\n")

success = 0
errors = 0

for idx, file_path in enumerate(failed_files, 1):
    file_path_obj = Path(file_path)
    basename = file_path_obj.name

    print(f"[{idx}/{len(failed_files)}] {basename}", flush=True)

    # Escape quotes for Elisp
    file_path_escaped = file_path.replace('"', '\\"')
    elisp_cmd = f'(denote-export-file "{file_path_escaped}")'

    try:
        result = subprocess.run(
            ['emacsclient', '-s', 'denote-export-daemon-1', '--eval', elisp_cmd],
            capture_output=True,
            text=True,
            timeout=180  # 180 seconds timeout
        )

        if result.returncode == 0 and 'SUCCESS:' in result.stdout:
            print(f"  ✓ Success", flush=True)
            success += 1
        else:
            print(f"  ✗ Failed", flush=True)
            errors += 1
    except subprocess.TimeoutExpired:
        print(f"  ✗ Timeout (180s)", flush=True)
        errors += 1
    except Exception as e:
        print(f"  ✗ Exception: {e}", flush=True)
        errors += 1

print(f"\n[Retry] Results: {success} success, {errors} errors")
sys.exit(0 if errors == 0 else 1)
#+end_src

*** Retry 실행 방법

#+begin_src bash
# 1. 실패 파일 경로 추출
grep "^✗" /tmp/meta-export.log | \
  sed 's/.*"\(\/home.*\.org\)".*/\1/' > /tmp/failed-files-paths.txt

# 2. Retry 스크립트 실행
python3 /tmp/retry-failed.py
#+end_src

** 실제 프로덕션 결과 (2025-10-31)

*** meta 폴더 530개 파일 처리

**** 1차 병렬 처리 (4 daemons, 60초 timeout)
- 성공: 513/530 (96.8%)
- 실패: 17개 (timeout)
- 시간: 2206초 (약 37분)
- 속도: 0.24 files/sec

**** 2차 개별 재처리 (180초 timeout)
- 성공: 17/17 (100%)
- 실패: 0개
- 추가 시간: 약 8분

**** 최종 결과 (v1: 60s timeout + 재시도)
- **총 파일**: 530개
- **성공**: 530/530 (100%)
- **실패**: 0개
- **총 시간**: 약 45분 (37분 + 재시도 8분)

**** v2 개선 (2025-10-31): Timeout 180초로 증가
- **전략**: 재시도 불필요하도록 충분한 timeout 설정
- **예상 결과**: 1회 실행으로 100% 성공
- **장점**: 워크플로우 단순화, 실패 파일 추출/재시도 불필요

*** 실패한 파일 특징 (v1 기준)
모두 대형 메타 파일이거나 복잡한 구조:
- 이맥스 (metameta)
- 인공지능 (metameta)
- 리스프 (metameta)
- syntopicon 시리즈
- 프로그래밍 코딩

→ 60초 timeout으로는 부족, 180초로 재시도 시 모두 성공

** 성능 비교

| 방식 | Daemons | Timeout | 속도 | meta 530개 |
|------|---------|---------|------|------------|
| Makefile (단일) | 1 | 60s | 0.1 files/sec | 88분 |
| Makefile (멀티) | 4 | 60s | 0.27 files/sec | 32분 |
| **Python (멀티, v1)** | **4** | **60s** | **0.24 files/sec** | **37분 + 재시도 8분** |
| **Python (멀티, v2)** | **4** | **180s** | **0.24 files/sec** | **37분 (100%)** |

** 핵심 장점

1. **Unicode 파일명 완벽 처리**
   - Python은 NBSP(U+00A0) 등 특수문자 네이티브 지원
   - bash 변수 전달 문제 없음

2. **독립적 프로세스**
   - ProcessPoolExecutor로 진짜 병렬 처리
   - 각 daemon이 독립적으로 동작

3. **에러 처리 강화**
   - timeout 처리
   - 실패 파일 자동 로깅
   - 재시도 스크립트 제공

4. **File-local variables 처리**
   - Interactive 프롬프트 차단
   - 모든 파일 자동 처리

** 다음 단계 (완료)
- [X] 전체 디렉토리(meta, bib, notes) export 테스트
- [X] File-local variables 처리 문제 해결
- [X] Python 병렬 처리 방식 구현
